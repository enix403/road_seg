{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8750fbe9-0730-474f-95f9-5652bb4daa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbd7c0a-0593-41d0-9e10-88efc49248f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision as tv\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms.v2.functional import to_pil_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362e8a8a-a7ae-4eb4-b9ad-170b3989ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_all\n",
    "from arch import RoadSegmentationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5344379e-3fa5-48b8-8ef8-59ad97257839",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d88772fc-c250-4ac4-94de-598ba1c31ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae26ff9f-7bad-4160-ad38-6cc9e109bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RoadSegmentationModel(\n",
    "    in_channels=3, out_channels=1,\n",
    "    num_filters=16, dropout=0.07\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b769395-594c-4557-9674-2ab489e2d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b26621-e184-490f-825d-d79a99da0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912594c-9b2c-4cfe-9218-868a5b27417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.37373125553131104\n",
      "2: 0.34911295771598816\n",
      "3: 0.3565100431442261\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.train() \n",
    "\n",
    "for epoch in range(1):\n",
    "    epoch_loss = 0.0\n",
    "    b = 0\n",
    "    for images, masks in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(images)\n",
    "        loss = loss_fn(logits, masks)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        b += 1\n",
    "        print(f\"{b}:\", loss.item())\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    lossi.append(epoch_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4677b-2653-4142-aa52-d9feb63f3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'checkpoints/unet_001.chk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "631434f8-716f-4469-8d8a-ce9a95ec5c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint = torch.load('checkpoints/unet_001.chk', weights_only=True)\n",
    "# model.load_state_dict(checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
